# TDL

### 9.17(일)
- 정말 바보 같은 부분
	- 명령어 안에 출력부분을 넣지 않았다.
- 불필요한 덧칠 작업
	- quick_sort를 하고, 스코어를 매기는데, 실은 인덱스를 매기는데 정렬은 필요 없다. quick_sort도 list로 돌아가서 참조하는 비용이 더 든다.

```c
valgrind still reachable 문제.

exit를 쓰면, still reachable까지는 잡을 필요 없다고 본다.
그런데 명백히 함수에서 나와 leak이 보이는데(바로 exit을 안하고 return을 하기 때문)
어차피 exit한다고 이걸 무시하는 건 찜찜해서 딱 leak부분만 잡아줬다.

+ 바로 exit을 안하고 return을 하는 이유는
호출 스택이 다른 함수들이 제각각 exit로 프로그램을 종료시키면
나중에 관리하기가 힘들다고 생각했기에 다 return문으로 main함수에서
exit을 하게끔 구조를 만들어줬다.
```
- 평가받기
- 평가 받기 전 
	- 불필요한 파일 있는지 확인
	- valgrind로 leak test
		- 인자 없을 때
		- 유효하지 않은 인자 (a, b)
		- 인자 중복
		- 정상적인 경우(3개, 100개)
		- mandatory, bonus 둘다.
	- 한번 쭉 보고, 이상한 거 없나 확인
	- 인자 테스트
	- norm
	- test
- checker
	- -2147483648 ~ 2147483647
	- ""1 -> 1로 본다
	- " " 2 -> error
	- "" 2 -> error
	- " " ""
	- 2147483647 " " -> OK
	- -2147483648 " " -> OK

### 9.16(금)

- gnl
	- get_next_line에서 오전 시간을 거의 다 썼다.
		- 일단 BUFFER_SIZE가 6이고, 표준입력으로 hello를 읽는다고 할 때, eof까지 읽게 된다. 하지만 read_size에는 이미 5까지 읽었기 때문에 eof를 인식하지 못한다. 그러면 eof를 또 받아야 한다. 그래야 hello라인을 받을 수 있다. (과연 gnl에서 eof를 2번 받아서 한 문장을 출력하는 게 맞는건가?)
		- 처음에는 eof를 받았을 떄 파일의 끝을 알려줬으니 한 번 만에 끝나는 게 맞다고 생각했다. 그런데, read함수 동작부분을 자세히보니 생각이 달라졌다
		- 표준입력으로 hello를 주고 eof를 주고, 또 eof를 주지 않는다면 거기에 덮어 쓸 수 있다!!! 
			- read함수는 중간에 들어온 eof동작을 인식하지 못한다. eof를 인식하지 못한다고 해서 코드가 잘못된 걸까? eof를 날린 순간 한 줄로 인식하고 끝나야 한다면, stdin으로 read를 읽을 때 eof를 날리고 다른 것으로 덮어쓸 수 있다는 게 설명이 안된다. (하지만 코드 사용자 입장에선 eof를 날렸을 때 종료가 되는 게 더 자연스럽다)
- 체커
	- 굉장히 쉽게 만들줄 알았는데, 생각보다 오래 걸렸다. 
		- check의 동작을 보고 했으면 간단하게 구현할 수 있었을텐데, 나는 checker가 gnl처럼 처음에는 pa\n을 받다가 마지막에는 개행이 없는 것도 받을 수 있다고 생각했다. (pa ctrl + D ctrl + D)
		- 그래서 받을 수 있는 최대 문자열을 크기 4로 제한하고(rrr + \n) 4, 3, 2에 대해서 ft_strnstr로 하드코딩해서 하나하나 예외를 잡아줬는데, 사실 그럴 필요가 없었다.
		- checker는 '\n'을 무조건 포함하여 받으니까 get_next_line이 알아서 쪼개지고, 따라서 ft_strnstr로 비교할 필요가 없고, strncmp로 비교하는 것만으로도 예외가 다 잡혀진다.

- Makefile
	- make (더미타겟 all을 찾는다) make bonus (make가 더미타겟 all을 찾으니 bonus흐름까지 더해서 2개의 흐름이 생기는줄 알았다)
		- make bonus 는 보너스 타깃만 찾는다.
	- Makefile안에 Makefile은 만들지 않는다. Makefile은 증분빌드기능. 즉 바뀐 부분만 컴파일하여 컴파일 시간을 단축하는 데 의미가 있다고 본다. 하지만, Makefile안에 Makefile을 하면 하위 종속성이 바뀌면 알아채지도 못하고, 매번 root Makefile이 make 될 때마다 하위 종속성들이 모두 재컴파일 된다(이건 또 하나의 리링크로 볼 수 있지 않을까?). 
	- 보너스 오브젝트 파일에 \ 이거 때문에 시간을 많이 소비했다. (탭으로면 하면 되는 건데, 그 사이에 스페이스가 들어가서 계속 object파일이 안들어갔던거 같다) 

### 9.15(목)
- 헤더를 기능별로 나누고 싶은데, 파일까지 norm기준으로 나눠지니까(5개) 생각대로 안된다. 내가 생각할 때 효율적이라고 생각하는 지점에서 타협해야겠다.
- 재귀 함수를 나누는 게 이렇게 오래 걸릴지 몰랐다. three sort 하드코딩된 부분도 나누는게 굉장히 귀찮았다. 
- 기존 main.c에서 gcc로 돌려가면서 테스트할 때 -Wall -Werror -Wextra옵션을 안줘서 불필요한 작업을 많이 한 것도 보였음.
- three_sort부분에 if문이 8개가 도는데 함수포인터를 사용해서 원하는 부분만 바로 접근할 수는 없을까? 해쉬테이블 같은걸로 불필요한 분기처리를 안했으면 좋겠는데.
- 기존 main.c에서 gcc로 돌려가면서 테스트할 때 -Wall -Werror -Wextra옵션을 안줘서 불필요한 작업을 많이 한 것도 보였
- 함수 네이밍이 이게 뭐냐? three_sort1~8 push_a_to_b1~5
- Makefile을 배운 것을 반영하려면
	- Makefile 안에 Makefile이 있어선 안된다(하위 종속성 관리를 못하기 때문)
	- #ifnef BONUS_FLAG 로 make 와 make_bonus dependency를 구분하게 되면, make -j 한번에 여러 작업을 하려는 옵션을 주면 터진다.
		- bonus, all인지에 따라서 같은 변수에 다른 변수 값을 준다. 즉 all과 bonus를 다른 동작을 하게 만들면 된다. 파일을 하나 만들어서 그걸로 리링크를 막는다. 


### 9.14(수)
- 함수 쪼개고 합치는 중...

### 9.13(화)
- 합치다가 터졌음. 합치기 전부터 다시 꼼꼼하게 봐야겠다. 도대체 어디가 안도는거지? 평균 횟수 10회 증가했네. 
 
### 9.12(월)
- 명령어 횟수
	- 5개   : 8 ~ 11
	- 100개 : 670 ~ 695
	- 500개 : 4730 (부등호 방향 바꾸면 4450, 대신 100개에서 커짐)
```
좋은 코드는 아니다.
malloc free같은 비싼 연산을 굉장히 빈번히 하고,
이렇게 자주 하는 이유가 함수를 재귀로 돌리기엔
그 구조가 한눈에 안들어왔기 때문이다.
정보가 담겨 있는 피봇노드를 만들고, 
그 피봇노드를 다 지워야 정렬이 완료되는 구조다.(재귀완료조건)
```

- 시행착오 정리.
	- 1. a->b로 보낼 때, 작은 피봇보다 작은 거 보내고, 큰 피봇보다 작은거 보내는 방식으로 했음. (그래서 리스트를 만들어, 이 순서를 기억했음)
		- a->b로 다 옮기면 a에 남은 거 정렬하고, b에는 pivot별로 덩어리가 저장되어 있음.
		- b->a로 보낼 때는 작은 덩어리위에 큰덩어리를 보내면 큰 덩어리부터 정렬할 수 가 없어서, 생각해낸게 1피봇을 기준으로 큰 것만 a로 보냈음.
			- (b->a로 보낼 떄 피봇2개를 기준으로 작은 피봇보다 큰 거 다 a로, 큰 피봇보다 작은거 ra했으면 됐겠네)
		- 완성했지만 결국 명령어를 구조적으로 줄일 수 없는 문제.
	- 2. b->a로 보낼 때 정렬된거 아래에 2(크기)이, 정렬된거 위에 3(크기)이 되었는데, 여기서 삽질을 많이함
		- 1. 3번이 정렬되는 크기가 아니면, 다시 2번 3번을 합쳐서 보냄.
			- 결국에 숫자가 크면 루프임.
		- 2. 3번부터 정렬하는데 2번의 rra(횟수)를 저장하는 로직 만들기가 까다로웠음. 
```
사실 수학적인 사고를 했으면, 이렇게 정렬했을 때 
복잡도를 눈대중으로 파악하고 
여러 시도를 할 수 있었을텐데,
어떻게 돌아가는지 생각이 잘 안되고, 
완성해야 명령어가 줄어드는 정도를 알 수 있었다.
```

### 9.11(일)
- 아, 뭔가 이제는 진짜 알 거 같아.
- (0, 18, 18)에서
	- (1, 6, 6) (1, 12 , 6) (0, 18, 6)으로 쪼개고
		- 1번이 2개로 늘어났다면, 1번 노드 갯수가 3보다 클 때는 두개를 합쳐줘야 한다. (1, 12, 12)
	- (0, 18, 6)부터 (1, 14, 2) (0, 16, 2) (0, 18, 2)해서 정렬하고.
		- 일단 여기서 큰 게 정렬된 거 아래에 있는데, 아래에 둬야 하는 이유는 갯수가 2개보다 크다면 합쳐줘야 한다 ex) 0, 18, 4로.
	- 그럼 아마 재귀문은 (pivot_node_a 갯수 < 1 && pivot_node_b 갯수 < 1)이여야 하고.
		- pivot_node_a 노드를 지워주고(정렬되지 않는다면 합쳐주고)
		- pivot_node_b 노드를 지워주고(정렬되지 않는다면 합쳐주고)
		- 합쳐줄 때 rra, rrb도 같이 해줘야 한다.
		- 이렇게 번갈아돌면서 해야할듯?
	
### 9.9(금)
- 순서와 피봇을 저장하는 insert_node삭제.
- push_stack
	- stack_a의 피봇과 정렬해야 하는 개수, stack_b의 피봇과 정렬해야하는 개수를 가지고 있는 구조체를 넘기는 구조.
	- 8부터 헛돈다.
	 
### 9.8(목)
- 3덩어리로 나눌 때 중간 피봇이 정렬된 거 아래에 있을 때 위에꺼 정렬하는 로직을 추가하고 나서 rr(ra, rb)를 하려고 하는데, 이게 생각보다 더 복잡하다.
 
### 9.7(수)
- 한번에 다 고려하면서 코드짜려고하니까 또 안되고, 일단 간단히 pivot으로 넘기고 돌리는 식으로 해서 돌아가게끔 하자.
	- 나는 pivot노드가 있으니 획기적으로 성능을 올릴 수 있을 거 같은데, 예를 들어 b에서 a로 보낼 때 pivot1을 기준으로 나눠지는데 (중간값이 위에 있고, 가장 적은 값이 정렬된 거 아래에 있을 때 이순간에 중간값을 미리 정렬할 수 있을 거 같아.(근데 이게 코드를 쓴다는게 굉장히 복잡하게 느껴짐. 천천히 생각해보는 걸로)
 
### 9.6(화)
- 구조 손봐야될 거 같다.
	- 개수만큼 2번 돌리는데, 한번 돌리면서 pivot2개로 정렬하는 식으로.

### 9/5(월)
- 코드에 근본적인 문제가 있음. (답이 없어 갈아 엎어야해)
	- a스택에 있는 걸 b스택에 모두 옮긴다. (a스택에 3개가 남을 때까지)
	- b스택에 있는 걸 모두 a스택에 옮긴다. (b스택에 3개가 남을 때까지)
	- 이를 계속 반복하면서 정렬한다.
- 아닐지도?지금 문제되는 정렬 케이스가 역순으로 정렬되어있을 때 가장 횟수가 많다.
	- 숫자가 적을 땐 bfs로 최적정렬 찾을 수 있겠는데?

- [.] 명령어 갯수를 더 낮춰야 한다.
	- [X] stack_a, stack_b에서 정렬된 것들이 아래에 없을 땐 rra(rrb)를 할 필요가 없다.
		- 5개	:	12
		- 10개	:	44
		- 50개	:	365
		- 100개 :	901
		- 500개 :	6230
		- 1000개:	14030
	- [ ] 지금은 2개 이하일 때만 정렬하는데 3개일 때도 바로 정렬할 수 있게 해야 한다.
		- 5개	:	11 ~ 13
		- 10개	:	25 ~ 36 (1->10은 24개, 10->1은 36개)
		- 50개	:	305 ~ 361 	
		- 100개	:	771 ~ 878
		- 500개	:	5661 ~ 6210
	- [ ] 해당 노드를 풀 때, a스택에 있는건 정렬되어 있을 때 b로 보내는 과정 없도록 하고, b스택에 있는 것이 역정렬 되어 있을 땐 피봇을 보내는 게 아니라 바로 보낸다?
	- [ ] 추가로 더 있을 듯.
- [ ] 완성되면 leak test
	- 정상적인 경우
		- 인자 없을 때
		- 정렬된 인자들 주어졌을 때
	- 비정상적인 경우
		- 이상한 인자 주어졌을 때
		- exit쓰니깐 크게 생각할 필요 없을듯.
- [ ] norm잡기
- bonus
	- [ ] 체커 만들기

### 9/4(일)
- 로직은 일단 완성(왕뿌듯)!
- 명령어 갯수
	- 5000개: 97800
	- 1000개: 15800
	- 500개 : 7100
	- 100개 : 1050
	- 50개	: 440
	- 10개	: 55
	- 5개	: 17 
- 코드는 이렇게 작동한다. (1~18)을 기준으로 생각하자. 일단 A_stack에서는 B_stack으로 pivot2개를 기준으로 보낸다. (3등분이 된다)
ex) 
				7~12
	13~18		1~6
	<A>			<\B>
- 이떄, 스택의 위치, 피봇값, 보낸 갯수를 저장하는 노드에 해당 정보를 추가한다. 처음에는 (0, 18, 18)에서 시작한다. 이는 앞에서부터 A스택에 18(pivot)보다 작은 갯수가 18개 있다는 것이다. 
- push_stack을 한번 거치면 위에 그림과 같이 pivot_list에는 (1, 6, 6) (1, 12, 6) (0, 18, 6) 노드가 만들어진다. (A스택[0]에서는 작은거부터 보낸다) 이 연결리스트를 스택처럼 사용한다. 즉, pivot_list에 가장 늦게 연결된 (0, 18, 6)부터 꺼내어 정렬한다.
- pivot_list의 노드를 보면 stack_a stack_b에 담겨있는 상태를 알 수 있다.
	- 1. (0, 18, 18)
	- 2. (1, 6, 6) (1, 12, 6) (0, 18, 6) 
	- (0, 18, 6)부터 정렬한다.
	- 3. (1, 14, 2) (1, 16, 2) (0, 18, 2)
		- 2개일 땐 더 나누지 않고 정렬하므로 (0, 18, 2) 노드를 제거하면서 stack_a에는 17, 18이 쌓이게 된다.
		- (1, 16, 2)는 역정렬된 상태로 pa하며 정렬하게 된다. (1, 14, 2)도 마찬가지다.
		- (0, 18, 6) 노드를 제거하면서 13 ~ 18이 정렬된 상태로 A스택에 담겨있다.
	- 마찬가지로 (1, 6, 6) (1, 12, 6)도 스택처럼 하나씩 푼다.
		- (1, 12, 6)은 2덩이로 풀릴 때 (1, 8, 2) (0, 9, 4) 이렇게 된다. 

### 오래 걸렸던 부분
- B에서 A로 보낼 때도 3덩이로 보낼려고 했다. 그렇게하면 A스택엔 중간 덩이 위에 제일 큰 덩이가 올라가있어 제일 큰 덩이를 먼저 정렬한다고 해도 중간에 정렬할 수 없는 중간 값이 끼어져 있다. 그래서 2덩이로 나누는 걸로 해결했다.
- sa를 단순히 데이터 교환하는 식으로 작성했다. 노드의 연결이 뒤바뀌지 않고 데이터 값만 바뀌면 결국 인자를 조금만 더 받아도 숫자가 이상하게 꼬이는데, 알고리즘 문제라 생각하고 알고리즘을 계속 고치려고했음.
- 잘 구현된 연결리스트를 사용해야 하는데, 탄탄하지 않은 자료구조를 쓰다보니 디버깅이 힘들었음.
- pivot_list에 노드를 넣어주는데, 2중 주소로 해줘야 삽입과 삭제가 깔끔히 되는데, 이런 기본적인 개념들이 미숙해서 헤맸다. 
- 재귀 고드를 짜면 작은 수부터 해봐야 하는데 처음부터 33개는 할 수 있다고 생각해서 코드가 더 느리게 나온듯 하다.
  
### 9/2(금)
- delete_node인지, insert_node인지 둘 중 하나 자료구조에서 터지는 거 같은데, 디버깅이 너무 빡세다. 알고리즘은 거의 완성된 거 같은데

### 9/1(목) -> 15일차네. 이렇게 오래할 줄 몰랐는데.
- 코드를 다시 짜야하나? 아이고 안돈다.
- 일단 코드를 고치면, 처음부터 낮은 숫자부터 다시 돌린다. 난 왜이리 재귀적으로 사고하는게 어렵지?
- 로직 정리 한번 해보고, 안되겠다 싶으면 갈아 엎고, 가능하면 코드가 더러워지더라도 짜보자.

### 로직 정리하기, 함수 정리도 해야겠다.
- 처음 정렬은 2피봇으로. 18까지 있으면
```
		7~12
13~18	1~6
[a]		[b]
```
- pivot_list는 이런식으로 만들어진다.
```
```
- 정렬해가면서 pivot_list는 이렇게 바껴간다
```
```


### 8/30(수)
- 1~18에서 터진다. 하나씩 뜯어서 고치면 될듯? 재귀적 사고가 정말 안되는듯. 잘하는 사람은 종료조건만 잡아주면서 돌리던데.
- 그리고 과제 공부하는 시간이 너무 적다. 저녁에 운영체제를 봐야 오전, 오후 과제에 집중할 수 있을듯. 
  
### 8/29(화)
- 차근차근 1~2 1~3 1~4 부터 돌려보는데 1~9에서 터진다 여기서부터 재귀함수가 정확히 돌아야 하기 때문. 지금은 sa가 제대로 안되는 거 같기도 하고, 
- `push_stack_a_r에서 **cmd_list를 받아야 해당 노드의 tool값을 바꿀 수 있는건가? 상관없기도 해보이는데` 일단 메인 로직 완성하고 테스트하기 

- 시간이 많이 걸리는게 코드가 지저분하고, 전에 맞았다고 생각하는 기능함수들에 사소한 에러가 있어서 잡아내는 게 오래걸린다. 
 
- sa가 제대로 안되는지, cmd_list를 앞에서부터 하나씩 없애는 게 제대로 동작 안하는지 내일 다시 봐야겠다. 

### 8/28(월)
- cmd_list를 손볼 필요가 있다. 연결리스트를 스택처럼 꺼내서 쓰는데, b->a로 보낼때 가장 먼저 보낸 노드, (11~22)를 3덩이로 쪼내서 a가 오는데 현재 코드에선 가장 적은 숫자가 먼저 정렬된다. 가장 적은 숫자가 정렬되는게 아니라. 18~22를 보낸 노드를 먼저 재귀로 정렬완료를 해야하는데, 이 경우를 잡으려면 flag를 쓰든 뭐를 하든 좀 더 생각해봐야겠다.


### 8/26(금)
- 결국에 코드가 분할정복으로 완성이 되야 하는데.
	- stack_a에 한 덩어리가 stack_b로 가면서 세덩이가 되고, stack_b의 각 덩어리들은 stack_a로 보내지면서 3덩이가 된다. 종료조건은 각 덩이들이 갯수가 2개이하일 때까지(2개이하일 때 정렬한다)
	- t_cmd_node를 스택처럼 사용한다. 
		- pivot, push_count, a->b or b->a flag 정보가 담긴 노드들을 꼬리쪽에서 하나씩 꺼내면서 갯수가 3개 이상이라면 기존 노드를 제거하고, 그 분할정복에 필요한 정보(pivot, push_count..)들을 다시 리스트에 추가해준다.
		- (11, 11, 1) -> (22, 11, 1) -> (25, 3, 1) -> (28, 3, 1) -> (29, 1, 1) -> (30, 1, 1) -> (31, 1, 1) -> (32, 1, 1)
		- (11, 11, 1) -> (22, 11, 1) -> (25, 3, 1) -> (28, 3, 1)
			- (28, 3, 1)노드를 제거하면서 3분할 하면서 생기는 정보들을 push_A에 보낸다 (2개 남았을 때 조건으로 종료조건을 잡았는데, 이게 3개의 덩어리가 쪼개지면서 구체적으로 어떻게 정렬이 될지는 아직 감이 안온다.
- A->B로 보내면서 다시 3분할.. 재귀

### 8/25(목)
- cmd_list를 만든다.
- cmd_list는 pivot1, pivot2를 이용하여 a->b로 보낸 1a->b로 보냈는지 b->a로 보냈는지 체크하는 것  2pivot 3push_count 을 기록하는 노드를 cmd_list에 푸쉬한다.
- cmd_list를 pop하듯이 하나씩 꺼내서, push_count <=2라면 정렬해버리고, 그렇지 않다면 다시 b->a로 보낸다. push_count가 낮아질 때까지 계속 반복하는데, 이부분을 코드로 구현하는 건 좀 떠 생각해봐야겠다.
- cmd_list에 모든 노드가 없어질 떄까지 반복한다. 한 노드를 없애기 위해선 push_count가 <= 2작을 떄까지 계속 pivot2개로 옆에 스택으로 보낸다.

### 8/24(수)
- 어떻게 해결해야 하는지 아직 감을 못잡고 있다.
- 1~33 score를 매기고, 
  pivot과 a->b로 보낸 수를 연결리스트에 푸쉬한다.
  (11, 11) -> (22, 11) -> (25, 3) -> (28, 2) -> (29, 1) -> (30, 1) -> (31, 1) -> (32, 1) 
- list가 비어있을 때까지 tail을 꺼내서 푸쉬하는 수가 2보다 적거나 같다면 푸쉬한다.

### 8/23(화)
- 재귀함수를 사용한다. (인자가 3개 이하 될때 정렬하고 종료하는 식으로 한다)
	- push_stack_b(t_list *list1, t_list *list2, pivot) : 처음에 pivot은 0이다.
	- push_stack_a(t_list *list1, t_list *list2, pivot)
		- 보낸 크기를 기억해서 push_stack_b인자에 추가해야 한다. 왜냐하면 a->b로 보내고, b->a로 보낼 때 a->b로 보낸 크기를 알고 있어야 하기 때문이다.
		- 뭔가 더 필요할 거 같은데 크게 생각이 나진 않는다.

- 정렬
	- 인자가 2개일땐 비교해서 sa연산을 하든가해서 정렬하고, 3개일 때 정렬 케이스를 나눈다.
		- 3개일 때 (1 - 2 - 3) (1 - 3 - 2) (2 - 1 - 3) (2 - 3 - 1) (3 - 1 - 2) (3 - 2 - 1)
	- 처음 스택을 정렬할 경우, 처음이 아닌 경우(정렬된 숫자가 있는 경우)에 정렬 과정이 달라야겠다.

- dangling pointer를 만나서 많이 헤메고 삽질 한 날.
-  pb를 delete_node a, new_node b를 해줬는데 그럴 필요 없이 연결부분만 바꿔주면 된다고 주변사람들이 알려줌.

### 8/22(월)
- 1~33까지 숫자가 있다고 했을 때, 
  stack_a (23 ~ 33), stack_b (12 ~ 22)
  							 (1 ~ 11)
	- 먼저 pivot을 기준으로 pivot보다 작은거 b로
	- pivot2보다 작은거 b로
	- 처음에 나누는 거는 재귀함수를 사용하는 게 아니라 그냥 구현하기.
	- stack_a 에서 다시 pivot2개를 설정. (여기선 재귀호출함수를 사용하는 게 좋겠다)
	- pivot 25, pivot 28(기존 pivot2 + size / 3)
	- pivot 30, pivot 32	
	- 그럼 stack_a size가 <= 2 작게되는데, 이걸 종료조건으로 하면 stack_a에 2개 정렬하고, 나머지는 stack_b 에 보낸상태가 된다.
	- 그럼 stack_b에는 (30 ~ 31), (28 ~ 29), (25 ~ 27), (22 ~ 24)가 있는데 어떤식으로 해야하지?
		- 기존에 a에서 b로 보낸 크기를 가지고 있는다? (3, 3, 2, 2)
		- 보낸 크기와 pivot값도 기억해야 할 듯? 
		- b에서 a로 보낼 때 크기 2랑 크기 2보다 클 때를 나누어 보낸다??????????????

---

- 정렬 속도가 중요한 게 아니다. 명령어를 가능한 적게 사용하는 게 중요하다.
- 어떻게하면 정렬 효율 좋게 최소한의 명령을 사용할 수 있을까?
	- greedy가 이 문제를 해결하는 데 가장 최적의 해답 같다.
		- 정렬하기 전에 최소한의 갯수를 탐색하니까
	- quick_sort로 이 문제를 해결해본다.
		- 명령어 횟수를 떠나 quick_sort는 시간복잡도가 좋기 때문이다.
- 정렬의 기준이 되는 pivot은 어떻게 설정할까?
	- pivot효율은 중간값이 좋다고 하더라.
		- 2개의 피봇을 사용해서 정렬해보자. (명령어 갯수를 낮추기 위해선 좀 더 비슷한 값끼리 모이게 할 필요가 있다.)
		- pivot값은 어떻게 구할 수 있을까?
			- 500개일 때 ranking을 매기면 1~500등까지 있다. 160등 기준으로 나누고 320등 기준으로 나눈다. 160등, 320 등의 값을 편하게 구하기 위해 정렬하여 ranking을 매긴다.
				- stack_a를 이미 정렬한 <temp> list를 만든다.
				- temp_list를 순회하면서 stack_a 원소들의 ranking을 매길 수 있다. (제일 작은 건 0, 제일 큰 건 size와 같도록)
